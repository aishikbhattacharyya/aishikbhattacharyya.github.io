<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 180 Project 5</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>

<h1 align="middle">CS 180: Intro to Computer Vision and Computational Photography, Fall 2024</h1>
<h1 align="middle">Project 5: Fun With Diffusion Models!</h1>
<h2 align="middle">Aishik Bhattacharyya</h2>

<div>

<h2 align="middle">Overview</h2>
	
In this project, we focus on shooting our own images and finding correspondences in between them to a lot of interesting things. First, we warp images and calculate its rectification, which allows us to see images as if they were posted in front of us, rather than in perspective. Second, we can use this information to blend images together and form panoramic views. We continued this in 4B, when we attempted to automate how we got our correspondence points and filtered them to get just the right amount in the right places.

<h1 align="middle">Part A: The Power of Diffusion Models!</h1>

<h3 align="middle">Setup</h3>
Here are some pictures from the rooftop of an apartment.

A homography is a 3x3 matrix which represents a transformation between a pair of images. We can recover a homography by using pairs of corresponding points. The points on the pictures above represent the corresponding points. To implement this function, I went through each pair of points and created a system of equations to obtain the homography matrix’s coefficients, of which there will be 9 values. I then solved it with a least squares solver and reshaped it into a 3x3 matrix.
<br>
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="proj5_images/part0_1.PNG" align="middle" width="400px"/>
        <figcaption align="middle"></figcaption>
	  </td>
    </tr>
  </table>
</div>

<h3 align="middle">Part 1.1: Implementing the Forward Process</h3>
In this part, we aim to take a clean image and produce a noisy image by sampling from a Gaussian. To accomplish this, I first get the alpha bar by getting the correct alpha_cumprod value at its respective timestep. Then, I calculate a random epsilon value and use all this info in equation 2 to get the noisy image.
<br>
  <div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="proj5_images/eq2.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Equation 2</figcaption>
      </td>
	<td>
        <img src="proj5_images/part1_1.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Noisy Campanile at various t-levels</figcaption>
      </td>
  </table>
	  
<h3 align="middle">Part 1.2: Classical Denoising</h3>
Now, we use Gaussian blur filtering to try to remove the noise with a kernel size of 5 and sigma of 1. This is primarily accomplished using torchvision.transforms.functional.gaussian_blur.
<br>
  <div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="proj5_images/part1_2.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Gaussian Blur Denoising at various t-levels</figcaption>
      </td>
  </table>
</div>

<h3 align="middle">Part 1.3: One Step Denoising</h3>
We use a pre-trained diffusion model to denoise, which is a UNet that’s been trained on a very large dataset. Using the UNet, we first estimate the noise in the noisy image. Then, we use the formula in equation 2 (as shown in 1.1) to create the clean image given the noisy image, using the noise estimate in the place of epsilon. This gives us a blurry image without the noise seen in 1.1, as well as providing a better output than 1.2.
<br>
  <div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="proj5_images/part1_3.PNG" align="middle" width="400px"/>
        <figcaption align="middle">One-Step Denoised Campanile at various t-levels</figcaption>
      </td>
  </table>
</div>

4: Iterative Denoising</h3>
In this part, instead of one-step denoising, we plan to denoise iteratively. We create a list of timesteps from 990 to 0, with intervals of 30. So at each denoising step, we use formula 3 to reduce the noise within the current iteration of the image. This is accomplished by calculating the alpha and beta values at the current and incoming timestep and running unet to get the noise estimate of the current image.
<br>
  <div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="proj5_images/eq3.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Equation 3</figcaption>
      </td>
  </table>
</div>
<br>
  <div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="proj5_images/part1.4_fifths.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Noisy image every 5th loop of denoising</figcaption>
      </td>
	<td>
        <img src="proj5_images/part1.4_clean.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Final Image for Iterative Denoising</figcaption>
</td>
  </table>
</div>
<br>
  <div align="middle">
  <table style="width=100%">
    <tr>
	<td>
        <img src="proj5_images/part1.4_onestep.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Final Image for Single Denoising Step</figcaption>
      </td>
 	</td>
	<td>
        <img src="proj5_images/part1.4_gaussian.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Final Image with Gaussian Blurring</figcaption>
      </td>
  </table>
</div>


<h3 align="middle">Part 1.

<h3 align="middle">Part 1.5: Diffusion Model Sampling</h3>
I use torch.randn to make noise and then call the iterative_denoise from the last part to generate the image.
<br>
  <div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="proj4_images/im4b3.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Matching Points between both images</figcaption>
      </td>
  </table>
</div>

<h3 align="middle">Part 1.6: Classifier Free Guidance</h3>
To use this technique, we use a lot of code written for iterative denoising. The difference is we have conditional and unconditional prompt embeddings. The unconditional prompt embedding is just null and we calculate the Unet for both these values instead of just one before. Then, we pull the noise estimates for both the Unets and use the formula below with the pre-specified scaling factor. The rest is the same.<br>
  <div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="proj4_images/result1.png" align="middle" width="400px"/>
        <figcaption align="middle">Result 1</figcaption>
      </td>
	<td>
        <img src="proj4_images/result2.png" align="middle" width="400px"/>
        <figcaption align="middle">Result 2</figcaption>
      </td>
	<td>
        <img src="proj4_images/result3.png" align="middle" width="400px"/>
        <figcaption align="middle">Result 3</figcaption>
      </td>
  </table>
</div>

<body>

</body>
</html>
