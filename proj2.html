<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 180 Project 2</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 180: Intro to Computer Vision and Computational Photography, Fall 2024</h1>
<h1 align="middle">Project 2: Fun with Filters and Frequencies!</h1>
<h2 align="middle">Aishik Bhattacharyya</h2>

<div>

<h2 align="middle">Overview</h2>
	
Sergei Mikhailovich Prokudin-Gorskii, as early as 1907, had a visionary idea--to take three exposures of every scene onto a glass plate with a red, blue, and green filter. He traveled the world and took color photographs everywhere, including the only color portrait of Leo Tolstoy. To honor his commitment, the goal of this project is to take these digitized glass plate images and form a single RGB color image.
<h3 align="middle">Part 1: Fun with Filters</h3>
<h4 align="middle">Part 1.1: Finite Difference Operator</h4>

In Part 1.1, we initialize the finite difference operator D_x and D_y. This is relevant because these will help us calculate the changes of intensity throughout the image, which will help us identify the edges. Then, we take our image and apply the convolutions in the x and y directions and calculate every pointâ€™s magnitude to help us get the aforementioned intensity measurements. Finally, to get the edges, I qualitatively tested different thresholds until I got one that minimized noise and just the cameraman.<br>
<br>
<div align="middle">
  <table style="width=100%">
    <tr>
	<td>
        <img src="proj2_images/x_grad.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Dx</figcaption>
	</td>
	<td>
        <img src="proj2_images/y_grad.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Dy</figcaption>
	</td>
	</tr>
	
	<td>
        <img src="proj2_images/magnitude.jpg" align="middle" width="400px"/>
        <figcaption align="middle">Magnitude</figcaption>
	</td>
      <td>
        <img src="proj2_images/binary.png" align="middle" width="400px"/>
        <figcaption align="middle">Binary Image</figcaption>
	</td>
    </tr>
  </table>
</div>

<h4 align="middle">Part 1.2: Derivative of Gaussian (DoG) Filter</h4>

In Part 1.2, I used a Gaussian filter to create a blurred version of the image and repeated the procedure from Part 1.1. The key differences were that the initial blurring suppressed a lot of noise without messing up edge detection and the edges were more boldly outlined. Next, I tried to accomplish this with a single convolution by using a derivative of Gaussian filters. The outcome was the same as before.<br>
<br>
<div align="middle">
  <table style="width=100%">
    <tr>
	<td>
        <img src="proj2_images/x_gradG.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Dx</figcaption>
	</td>
	<td>
        <img src="proj2_images/y_gradG.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Dy</figcaption>
	</td>
	</tr>
	
	<td>
        <img src="proj2_images/magnitudeG.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Magnitude</figcaption>
	</td>
      <td>
        <img src="proj2_images/binaryG.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Binary Image</figcaption>
	</td>
    </tr>
  </table>
</div>
</body>
</html>
