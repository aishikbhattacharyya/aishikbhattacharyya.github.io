<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 180 Project 2</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 180: Intro to Computer Vision and Computational Photography, Fall 2024</h1>
<h1 align="middle">Project 2: Fun with Filters and Frequencies!</h1>
<h2 align="middle">Aishik Bhattacharyya</h2>

<div>

<h2 align="middle">Overview</h2>
	
Sergei Mikhailovich Prokudin-Gorskii, as early as 1907, had a visionary idea--to take three exposures of every scene onto a glass plate with a red, blue, and green filter. He traveled the world and took color photographs everywhere, including the only color portrait of Leo Tolstoy. To honor his commitment, the goal of this project is to take these digitized glass plate images and form a single RGB color image.
<h3 align="middle">Part 1: Fun with Filters</h3>
<h4 align="middle">Part 1.1: Finite Difference Operator</h4>

In Part 1.1, we initialize the finite difference operator D_x and D_y. This is relevant because these will help us calculate the changes of intensity throughout the image, which will help us identify the edges. Then, we take our image and apply the convolutions in the x and y directions and calculate every point’s magnitude to help us get the aforementioned intensity measurements. Finally, to get the edges, I qualitatively tested different thresholds until I got one that minimized noise and just the cameraman.<br>
<br>
<div align="middle">
  <table style="width=100%">
    <tr>
	<td>
        <img src="proj2_images/x_grad.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Dx</figcaption>
	</td>
	<td>
        <img src="proj2_images/y_grad.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Dy</figcaption>
	</td>
	</tr>
	
	<td>
        <img src="proj2_images/magnitude.jpg" align="middle" width="400px"/>
        <figcaption align="middle">Magnitude</figcaption>
	</td>
      <td>
        <img src="proj2_images/binary.png" align="middle" width="400px"/>
        <figcaption align="middle">Binary Image</figcaption>
	</td>
    </tr>
  </table>
</div>

<h4 align="middle">Part 1.2: Derivative of Gaussian (DoG) Filter</h4>

In Part 1.2, I used a Gaussian filter to create a blurred version of the image and repeated the procedure from Part 1.1. The key differences were that the initial blurring suppressed a lot of noise without messing up edge detection and the edges were more boldly outlined.<br>
<br>
<div align="middle">
  <table style="width=100%">
    <tr>
	<td>
        <img src="proj2_images/x_gradG.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Dx</figcaption>
	</td>
	<td>
        <img src="proj2_images/y_gradG.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Dy</figcaption>
	</td>
	</tr>
	
	<td>
        <img src="proj2_images/magnitude_G.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Magnitude</figcaption>
	</td>
      <td>
        <img src="proj2_images/binaryG.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Binary Image</figcaption>
	</td>
    </tr>
  </table>
</div>

<br>
Next, I tried to accomplish this with a single convolution by using a derivative of Gaussian filters. The outcome was the same as before.
<div align="middle">
  <table style="width=100%">
	<tr>
	<td>
        <img src="proj2_images/singleConv.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Single Convolution Result</figcaption>
	</td>
    </tr>
  </table>
</div>

<h3 align="middle">Part 2: Fun with Frequencies!</h3>
<h4 align="middle">Part 2.1: Image "Sharpening"</h4>

In Part 2.1, we aim to sharpen a blurry image. To sharpen an image, we need to take advantage of its high frequencies. This can be done by running an image through a low pass filter and then subtracting it from the original image. We take these high frequencies and amplify it so that the image appears sharper. Because this is a RGB image, we apply this sharpening filter to each layer and combine it all at the end.<br>
<div align="middle">
  <table style="width=100%">
    <tr>
	<td>
        <img src="proj2_images/taj.jpg" align="middle" width="400px"/>
        <figcaption align="middle">Original</figcaption>
	</td>
	<td>
        <img src="proj2_images/taj2.PNG" align="middle" width="400px"/>
        <figcaption align="middle">alpha=2</figcaption>
	</td>
	<td>
        <img src="proj2_images/taj6.PNG" align="middle" width="400px"/>
        <figcaption align="middle">alpha=6</figcaption>
	</td>
	</tr>
</table>
</div>
<br>
Then, I uploaded an image of a bird, with very sharp outlines, to see what would happen if I took a sharp image, blurred it, and then sharpened it. The result was that the resulting image was a bit blurrier than the original. In the initial process of blurring, some fine details were lost and could not be recovered.
<div align="middle">
  <table style="width=100%">
    <tr>
	<td>
        <img src="proj2_images/bird.jpg" align="middle" width="400px"/>
        <figcaption align="middle">Original</figcaption>
	</td>
	<td>
        <img src="proj2_images/blurred_bird.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Blurred</figcaption>
	</td>
	<td>
        <img src="proj2_images/blurred_sharped_bird.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Blurred, Sharpened</figcaption>
	</td>
	</tr>
</table>
</div>

<h4 align="middle">Part 2.2: Hybrid Images</h4>

In Part 2.2, the goal is to create hybrid images by combining the high frequency portions of one image and the low frequency portions of another. Depending on the distance we end up looking at the final image, different parts will be highlighted and viewed. First, we must identify the points to align each image. For example, the cat image was roasted and the human face was not. For that combination of images, I chose to use their eyes for alignment. For the other ones, I picked the left eye and chin. Then, I used a Gaussian kernel to convolve the images and get its high and low frequency portions. Those portions are then combined to form the final image.<div align="middle">
<br>
<table style="width=100%">
    <tr>
	<td>
        <img src="proj2_images/anakin1.jpg" align="middle" width="400px"/>
        <figcaption align="middle">Anakin</figcaption>
	</td>
	<td>
        <img src="proj2_images/vader1.jpg" align="middle" width="400px"/>
        <figcaption align="middle">Darth Vader</figcaption>
	</td>
	<td>
        <img src="proj2_images/anakinvader.jfif" align="middle" width="400px"/>
        <figcaption align="middle">Combined</figcaption>
	</td>
	</tr>
</table>
<table style="width=100%">
    <tr>
	<td>
        <img src="proj2_images/aaron.jfif" align="middle" width="400px"/>
        <figcaption align="middle">Aaron Rodgers</figcaption>
	</td>
	<td>
        <img src="proj2_images/goat.jpg" align="middle" width="400px"/>
        <figcaption align="middle">Goat</figcaption>
	</td>
	<td>
        <img src="proj2_images/goataaron.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Combined</figcaption>
	</td>
	</tr>
</table>
</div>
<br>
I chose to show the 2D fourier transform with the Anakain/Vader pictures.
<div align="middle">
<table style="width=100%">
    <tr>
	<td>
        <img src="proj2_images/filter1.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Anakin Input</figcaption>
	</td>
	<td>
        <img src="proj2_images/filterlow.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Anakin Filtered</figcaption>
	</td>
    </tr>
	<tr>
	<td>
        <img src="proj2_images/filter2.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Vader Input</figcaption>
	</td>
	<td>
        <img src="proj2_images/filterhigh.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Vader Filtered</figcaption>
	</td>
	</tr>
<tr>
	<td>
        <img src="proj2_images/filterhybrid.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Hybrid</figcaption>
	</td>
	</tr>
</table>
</div>
<br>
This was a failiure because Mr. Pops' head is way too big compared to Pinocchio's. After some trial and error, I was able to align their eyes such that Pinocchio's nose looks like Mr. Pops'. But since one face is so much bigger, this hybrid image does not work.
<div align="middle">
<table style="width=100%">
    <tr>
	<td>
        <img src="proj2_images/mrpops.jpg" align="middle" width="400px"/>
        <figcaption align="middle">Anakin Input</figcaption>
	</td>
	<td>
        <img src="proj2_images/pinocchio.jpg" align="middle" width="400px"/>
        <figcaption align="middle">Anakin Filtered</figcaption>
	</td>
    </tr>
	<tr>
	<td>
        <img src="proj2_images/failiure.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Vader Input</figcaption>
	</td>
	</tr>
</table>
</div>
	
<h4 align="middle">Part 2.3: Gaussian and Laplacian Stacks</h4>
<br>
In Part 2.3, I had to create my own Gaussian and Laplacian stacks and blend together two images with the help of these stacks. To create my stacks, I started by creating a Gaussian stack starting with the original image and creating a Gaussian kernel and convolving with it for all layers of the image. Then, I subtracted the most recent Gaussian value with the last one and continued doing so to create my Laplacian stack. To blend images, I got a Gaussian and Laplacian stack for the apple and orange, as well as created a vertical mask, which is half black and half white, and calculated its Gaussian stack. I kept track of my blended sum and at every depth level, I added the product of the current mask’s Gaussian layer and one image’s current laplacian level, as well as 1 minus the current mask’s Gaussian layer and the other image’s current laplacian level. I picked which one to multiply by based on which side was black and white. I kept a running sum and at the end I did the same process to the last Gaussian layer and added it to my final sum. I made sure to clip my values to make sure all the numbers were valid to output.
<br>
<div align="middle">
<table style="width=100%">
    <tr>
	<td>
        <img src="proj2_images/0aa (1).png" align="middle" width="400px"/>
        <figcaption align="middle">Level 0</figcaption>
	</td>
	<td>
        <img src="proj2_images/2aa (1).png" align="middle" width="400px"/>
        <figcaption align="middle">Level 2</figcaption>
	</td>
	<td>
        <img src="proj2_images/4aa (1).png" align="middle" width="400px"/>
        <figcaption align="middle">Level 4</figcaption>
	</td>
	</tr>
    <tr>
	<td>
        <img src="proj2_images/orapple.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Orapple</figcaption>
	</td>
	</tr>
</table>
</div>

<h4 align="middle">Part 2.4: Multiresolution Blending</h4>
<br>
In Part 2.4, I used all my logic from Part 2.3 with a little tweaks. The code from Part 2.3 works successfully to create the orapple, but that uses a trivial vertical mask. In my first test case, I try to put an open, smiling mouth on Doctor Strange. This required me to first create an irregular mask which highlights the mouth as white and the rest black. One error I ran into was not adding the blended sum properly because I was multiplying the wrong, switched mask values with their laplacian values, leading me to only see the mouth. After fixing that I got the following.<br>
<br>
<div align="middle">
<table style="width=100%">
    <tr>
	<td>
        <img src="proj2_images/spongebobFinal.jpg" align="middle" width="400px"/>
        <figcaption align="middle">Spongebob</figcaption>
	</td>
	<td>
        <img src="proj2_images/mcchickenFinal.jpg" align="middle" width="400px"/>
        <figcaption align="middle">McChicken</figcaption>
	</td>
	<td>
        <img src="proj2_images/spongeChickenFinal.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Spongebob Enamored by the McChicken</figcaption>
	</td>
	</tr>
    <tr>
	<td>
        <img src="proj2_images/strange2.jpg" align="middle" width="400px"/>
        <figcaption align="middle">Doctor Strange</figcaption>
	</td>
	<td>
        <img src="proj2_images/mouthFinal.jpg" align="middle" width="400px"/>
        <figcaption align="middle">Mouth</figcaption>
	</td>
	<td>
        <img src="proj2_images/strangeFinal.PNG" align="middle" width="400px"/>
        <figcaption align="middle">Mouth on Doctor Strange</figcaption>
	</td>
	</tr>
</table>
</div>
</body>
</html>
